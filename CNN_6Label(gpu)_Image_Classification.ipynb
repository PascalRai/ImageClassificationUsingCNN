{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1da0140",
   "metadata": {},
   "source": [
    "# 1. Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f37afe",
   "metadata": {},
   "source": [
    "We need to model a NN that can classify whether a given image is Building, Forest, Glacier, Mountain, Sea, or Street.\n",
    "\n",
    "We are using CNN to train our model. (using a gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb69544",
   "metadata": {},
   "source": [
    "# 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f82d8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eddcdf8",
   "metadata": {},
   "source": [
    "### Checking number of gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f7cf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd95e6db",
   "metadata": {},
   "source": [
    "# 3. Getting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56894449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 files belonging to 6 classes.\n",
      "Using 11228 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory('seg_train',\n",
    "                                                      validation_split = 0.2,\n",
    "                                                       subset = 'training',\n",
    "                                                       seed = 123,\n",
    "                                                       image_size = (150, 150),\n",
    "                                                       batch_size = 100\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d87761c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 files belonging to 6 classes.\n",
      "Using 2806 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory('seg_train',\n",
    "                                                      validation_split = 0.2,\n",
    "                                                       subset = 'validation',\n",
    "                                                       seed = 123,\n",
    "                                                       image_size = (150, 150),\n",
    "                                                       batch_size = 100\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46743cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c93f6",
   "metadata": {},
   "source": [
    "# 4. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a46cb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 146, 146, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 69, 69, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 34, 34, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 56)        16184     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 56)        28280     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 56)        28280     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 56)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 128)       64640     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 10, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 1,007,422\n",
      "Trainable params: 1,007,422\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(150, 150, 3)))\n",
    "model.add(layers.Conv2D(16,kernel_size=(3,3),activation='relu'))\n",
    "model.add(layers.Conv2D(16,kernel_size=(3,3), activation = 'relu',))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(32,kernel_size=(3,3), activation = 'relu',))\n",
    "model.add(layers.Conv2D(32,kernel_size=(3,3), activation = 'relu',))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(56,kernel_size=(3,3), activation = 'relu',))\n",
    "model.add(layers.Conv2D(56,kernel_size=(3,3), activation = 'relu',))\n",
    "model.add(layers.Conv2D(56,kernel_size=(3,3), activation = 'relu',))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(128,kernel_size=(3,3), activation = 'relu',))\n",
    "model.add(layers.Conv2D(128,kernel_size=(3,3), activation = 'relu',))\n",
    "model.add(layers.Conv2D(128,kernel_size=(3,3), activation = 'relu',))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, 'relu'))\n",
    "model.add(layers.Dense(128, 'relu'))\n",
    "model.add(layers.Dense(6,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcbb0b9",
   "metadata": {},
   "source": [
    "# 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4860dded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - 41s 252ms/step - loss: 1.3382 - accuracy: 0.4107 - val_loss: 1.0304 - val_accuracy: 0.5606\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 26s 231ms/step - loss: 1.0307 - accuracy: 0.5688 - val_loss: 0.9245 - val_accuracy: 0.6194\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 26s 227ms/step - loss: 0.9030 - accuracy: 0.6372 - val_loss: 0.8843 - val_accuracy: 0.6475\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 26s 226ms/step - loss: 0.8434 - accuracy: 0.6687 - val_loss: 0.7766 - val_accuracy: 0.7067\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 26s 227ms/step - loss: 0.7605 - accuracy: 0.7065 - val_loss: 0.7374 - val_accuracy: 0.7270\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 26s 227ms/step - loss: 0.6829 - accuracy: 0.7406 - val_loss: 0.7765 - val_accuracy: 0.7167\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 26s 229ms/step - loss: 0.6483 - accuracy: 0.7525 - val_loss: 0.6391 - val_accuracy: 0.7758\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 26s 228ms/step - loss: 0.5817 - accuracy: 0.7822 - val_loss: 0.6659 - val_accuracy: 0.7619\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 26s 228ms/step - loss: 0.5403 - accuracy: 0.8004 - val_loss: 0.6615 - val_accuracy: 0.7730\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 26s 228ms/step - loss: 0.5159 - accuracy: 0.8095 - val_loss: 0.6160 - val_accuracy: 0.7830\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 26s 228ms/step - loss: 0.4834 - accuracy: 0.8226 - val_loss: 0.6692 - val_accuracy: 0.7769\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 26s 229ms/step - loss: 0.4634 - accuracy: 0.8337 - val_loss: 0.5822 - val_accuracy: 0.8001\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 26s 231ms/step - loss: 0.4139 - accuracy: 0.8474 - val_loss: 0.6570 - val_accuracy: 0.7901\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 26s 233ms/step - loss: 0.4016 - accuracy: 0.8568 - val_loss: 0.6681 - val_accuracy: 0.7922\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 26s 231ms/step - loss: 0.3682 - accuracy: 0.8663 - val_loss: 0.6499 - val_accuracy: 0.7929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1278dfc8100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          epochs=100,\n",
    "          validation_data = val_ds,\n",
    "          callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66778315",
   "metadata": {},
   "source": [
    "train_loss = 0.4634\n",
    "\n",
    "val_loss = 0.5822\n",
    "\n",
    "As, val_loss is only slighly higher than train_loss.<br>\n",
    "**The model is not overfitted.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d306ca20",
   "metadata": {},
   "source": [
    "# 6. testing and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee57e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory('seg_test',\n",
    "                                                       image_size = (150, 150),\n",
    "                                                       batch_size = 100\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd817305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 3s 89ms/step - loss: 0.6656 - accuracy: 0.7760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.665601372718811, 0.7760000228881836]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097be970",
   "metadata": {},
   "source": [
    "test_loss = 0.66\n",
    "\n",
    "And the **accuracy of the model is about 78 %.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca8ffa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
